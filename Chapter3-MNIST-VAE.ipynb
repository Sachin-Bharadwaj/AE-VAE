{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from models.VAE import VariationalAutoencoder\n",
    "from utils.loaders import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "SECTION = 'vae'\n",
    "RUN_ID = '0002'\n",
    "DATA_NAME = 'digits'\n",
    "RUN_FOLDER = './run/{}/'.format(SECTION)\n",
    "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
    "\n",
    "p = pathlib.Path(RUN_FOLDER)\n",
    "\n",
    "if not p.exists():\n",
    "    p.mkdir(parents=True, exist_ok=False)\n",
    "    (p/'viz').mkdir(parents=True, exist_ok=False)\n",
    "    (p/'images').mkdir(parents=True, exist_ok=False)\n",
    "    (p/'weights').mkdir(parents=True, exist_ok=False)\n",
    "    \n",
    "MODE =  'build' #'load' #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(\n",
    "    input_dim = (28,28,1)\n",
    "    , encoder_conv_filters = [32,64,64, 64]\n",
    "    , encoder_conv_kernel_size = [3,3,3,3]\n",
    "    , encoder_conv_strides = [1,2,2,1]\n",
    "    , decoder_conv_t_filters = [64,64,32,1]\n",
    "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
    "    , decoder_conv_t_strides = [1,2,2,1]\n",
    "    , z_dim = 2\n",
    ")\n",
    "\n",
    "if MODE == 'build':\n",
    "    vae.save(RUN_FOLDER)\n",
    "else:\n",
    "    vae.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)         (None, 28, 28, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 28, 28, 32)   0           encoder_conv_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)         (None, 14, 14, 64)   18496       leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 14, 14, 64)   0           encoder_conv_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 7, 7, 64)     0           encoder_conv_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)         (None, 7, 7, 64)     36928       leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 7, 7, 64)     0           encoder_conv_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 3136)         0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            6274        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var (Dense)                 (None, 2)            6274        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n",
      "                                                                 log_var[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 105,220\n",
      "Trainable params: 105,220\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vae.encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae.decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def data_set(xdata, ydata=None): # just returns a tuple\n",
    "    return (xdata, ydata)\n",
    "\n",
    "def sampler(dataset, bs, shuffle=True):\n",
    "    '''\n",
    "    [1] datasetlen : tuple: (xdata, ydata)\n",
    "    [2] bs: batchsize\n",
    "    [3] shuffle: Boolean\n",
    "    '''\n",
    "    n = len(dataset[0])\n",
    "    idx = np.random.permutation(n) if shuffle else np.arange(n)\n",
    "    while True:\n",
    "        for i in range(0,n,bs):\n",
    "            yield idx[i:i+bs]\n",
    "\n",
    "def data_gen(dataset, samp):\n",
    "    ''' Inputs\n",
    "    [1] dataset: tuple: (xdata, ydata)\n",
    "    [2] samp: generator object for the sampler function\n",
    "    \n",
    "    '''    \n",
    "    idxs = next(samp)\n",
    "    while True:\n",
    "        yield (dataset[0][idxs], dataset[1][idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 32\n",
    "dataset = data_set(x_train,x_train)\n",
    "sampler_obj = sampler(dataset, bs, shuffle=True)\n",
    "data_gen_obj = data_gen(dataset, sampler_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "R_LOSS_FACTOR = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(LEARNING_RATE, R_LOSS_FACTOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "PRINT_EVERY_N_BATCHES = 100\n",
    "INITIAL_EPOCH = 0\n",
    "DATALEN = len(dataset[0])\n",
    "STEPS_PER_EPOCH = DATALEN//BATCH_SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 30.1552 - vae_r_loss: 24.6273 - vae_kl_loss: 5.5280\n",
      "\n",
      "Epoch 00001: saving model to ./run/vae/0002_digits\\weights/weights-001-30.16.h5\n",
      "\n",
      "Epoch 00001: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 2/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 10.4509 - vae_r_loss: 4.6123 - vae_kl_loss: 5.8385\n",
      "\n",
      "Epoch 00002: saving model to ./run/vae/0002_digits\\weights/weights-002-10.45.h5\n",
      "\n",
      "Epoch 00002: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 3/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 9.1123 - vae_r_loss: 3.5053 - vae_kl_loss: 5.6070\n",
      "\n",
      "Epoch 00003: saving model to ./run/vae/0002_digits\\weights/weights-003-9.11.h5\n",
      "\n",
      "Epoch 00003: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 4/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 8.3987 - vae_r_loss: 2.9088 - vae_kl_loss: 5.4899\n",
      "\n",
      "Epoch 00004: saving model to ./run/vae/0002_digits\\weights/weights-004-8.40.h5\n",
      "\n",
      "Epoch 00004: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 5/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 7.7577 - vae_r_loss: 2.3432 - vae_kl_loss: 5.4144\n",
      "\n",
      "Epoch 00005: saving model to ./run/vae/0002_digits\\weights/weights-005-7.76.h5\n",
      "\n",
      "Epoch 00005: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 6/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 7.3626 - vae_r_loss: 2.0149 - vae_kl_loss: 5.3477\n",
      "\n",
      "Epoch 00006: saving model to ./run/vae/0002_digits\\weights/weights-006-7.36.h5\n",
      "\n",
      "Epoch 00006: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 7/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 7.1365 - vae_r_loss: 1.8478 - vae_kl_loss: 5.2887\n",
      "\n",
      "Epoch 00007: saving model to ./run/vae/0002_digits\\weights/weights-007-7.14.h5\n",
      "\n",
      "Epoch 00007: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 8/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 6.9729 - vae_r_loss: 1.7356 - vae_kl_loss: 5.2373\n",
      "\n",
      "Epoch 00008: saving model to ./run/vae/0002_digits\\weights/weights-008-6.97.h5\n",
      "\n",
      "Epoch 00008: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 9/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 6.8390 - vae_r_loss: 1.6417 - vae_kl_loss: 5.1974\n",
      "\n",
      "Epoch 00009: saving model to ./run/vae/0002_digits\\weights/weights-009-6.84.h5\n",
      "\n",
      "Epoch 00009: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 10/200\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 6.7507 - vae_r_loss: 1.5753 - vae_kl_loss: 5.1754\n",
      "\n",
      "Epoch 00010: saving model to ./run/vae/0002_digits\\weights/weights-010-6.75.h5\n",
      "\n",
      "Epoch 00010: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 11/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 6.6539 - vae_r_loss: 1.5112 - vae_kl_loss: 5.1427\n",
      "\n",
      "Epoch 00011: saving model to ./run/vae/0002_digits\\weights/weights-011-6.65.h5\n",
      "\n",
      "Epoch 00011: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 12/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 6.6036 - vae_r_loss: 1.4820 - vae_kl_loss: 5.12161s - loss: 6.6034 \n",
      "\n",
      "Epoch 00012: saving model to ./run/vae/0002_digits\\weights/weights-012-6.60.h5\n",
      "\n",
      "Epoch 00012: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 13/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 6.5176 - vae_r_loss: 1.4129 - vae_kl_loss: 5.1047\n",
      "\n",
      "Epoch 00013: saving model to ./run/vae/0002_digits\\weights/weights-013-6.52.h5\n",
      "\n",
      "Epoch 00013: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 14/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 6.4527 - vae_r_loss: 1.3807 - vae_kl_loss: 5.0719\n",
      "\n",
      "Epoch 00014: saving model to ./run/vae/0002_digits\\weights/weights-014-6.45.h5\n",
      "\n",
      "Epoch 00014: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 15/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 6.3951 - vae_r_loss: 1.3387 - vae_kl_loss: 5.0565\n",
      "\n",
      "Epoch 00015: saving model to ./run/vae/0002_digits\\weights/weights-015-6.40.h5\n",
      "\n",
      "Epoch 00015: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 16/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 6.3494 - vae_r_loss: 1.3009 - vae_kl_loss: 5.0485\n",
      "\n",
      "Epoch 00016: saving model to ./run/vae/0002_digits\\weights/weights-016-6.35.h5\n",
      "\n",
      "Epoch 00016: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 17/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 6.2914 - vae_r_loss: 1.2759 - vae_kl_loss: 5.0155\n",
      "\n",
      "Epoch 00017: saving model to ./run/vae/0002_digits\\weights/weights-017-6.29.h5\n",
      "\n",
      "Epoch 00017: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 18/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 6.2604 - vae_r_loss: 1.2585 - vae_kl_loss: 5.0018\n",
      "\n",
      "Epoch 00018: saving model to ./run/vae/0002_digits\\weights/weights-018-6.26.h5\n",
      "\n",
      "Epoch 00018: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 19/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 6.2138 - vae_r_loss: 1.2289 - vae_kl_loss: 4.9849\n",
      "\n",
      "Epoch 00019: saving model to ./run/vae/0002_digits\\weights/weights-019-6.21.h5\n",
      "\n",
      "Epoch 00019: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 20/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 6.1963 - vae_r_loss: 1.2072 - vae_kl_loss: 4.9891\n",
      "\n",
      "Epoch 00020: saving model to ./run/vae/0002_digits\\weights/weights-020-6.20.h5\n",
      "\n",
      "Epoch 00020: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 21/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 6.1478 - vae_r_loss: 1.1796 - vae_kl_loss: 4.9683\n",
      "\n",
      "Epoch 00021: saving model to ./run/vae/0002_digits\\weights/weights-021-6.15.h5\n",
      "\n",
      "Epoch 00021: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 22/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 6.0502 - vae_r_loss: 1.0901 - vae_kl_loss: 4.96011s - loss: 6\n",
      "\n",
      "Epoch 00022: saving model to ./run/vae/0002_digits\\weights/weights-022-6.05.h5\n",
      "\n",
      "Epoch 00022: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 23/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.9952 - vae_r_loss: 1.0437 - vae_kl_loss: 4.9514\n",
      "\n",
      "Epoch 00023: saving model to ./run/vae/0002_digits\\weights/weights-023-6.00.h5\n",
      "\n",
      "Epoch 00023: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 24/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.9676 - vae_r_loss: 1.0332 - vae_kl_loss: 4.9344\n",
      "\n",
      "Epoch 00024: saving model to ./run/vae/0002_digits\\weights/weights-024-5.97.h5\n",
      "\n",
      "Epoch 00024: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 25/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.9390 - vae_r_loss: 1.0094 - vae_kl_loss: 4.9296\n",
      "\n",
      "Epoch 00025: saving model to ./run/vae/0002_digits\\weights/weights-025-5.94.h5\n",
      "\n",
      "Epoch 00025: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 26/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.9179 - vae_r_loss: 1.0019 - vae_kl_loss: 4.9160\n",
      "\n",
      "Epoch 00026: saving model to ./run/vae/0002_digits\\weights/weights-026-5.92.h5\n",
      "\n",
      "Epoch 00026: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 27/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.8729 - vae_r_loss: 0.9691 - vae_kl_loss: 4.9039\n",
      "\n",
      "Epoch 00027: saving model to ./run/vae/0002_digits\\weights/weights-027-5.87.h5\n",
      "\n",
      "Epoch 00027: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 28/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.8385 - vae_r_loss: 0.9605 - vae_kl_loss: 4.8780\n",
      "\n",
      "Epoch 00028: saving model to ./run/vae/0002_digits\\weights/weights-028-5.84.h5\n",
      "\n",
      "Epoch 00028: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 29/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.8449 - vae_r_loss: 0.9567 - vae_kl_loss: 4.8882\n",
      "\n",
      "Epoch 00029: saving model to ./run/vae/0002_digits\\weights/weights-029-5.84.h5\n",
      "\n",
      "Epoch 00029: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 30/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 31s 16ms/step - loss: 5.8524 - vae_r_loss: 0.9547 - vae_kl_loss: 4.8977\n",
      "\n",
      "Epoch 00030: saving model to ./run/vae/0002_digits\\weights/weights-030-5.85.h5\n",
      "\n",
      "Epoch 00030: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 31/200\n",
      "1875/1875 [==============================] - 31s 16ms/step - loss: 5.8247 - vae_r_loss: 0.9374 - vae_kl_loss: 4.8873\n",
      "\n",
      "Epoch 00031: saving model to ./run/vae/0002_digits\\weights/weights-031-5.82.h5\n",
      "\n",
      "Epoch 00031: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 32/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.8138 - vae_r_loss: 0.9293 - vae_kl_loss: 4.8845\n",
      "\n",
      "Epoch 00032: saving model to ./run/vae/0002_digits\\weights/weights-032-5.81.h5\n",
      "\n",
      "Epoch 00032: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 33/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.7821 - vae_r_loss: 0.9090 - vae_kl_loss: 4.87322s - loss: 5.7880 - vae_r_loss: \n",
      "\n",
      "Epoch 00033: saving model to ./run/vae/0002_digits\\weights/weights-033-5.78.h5\n",
      "\n",
      "Epoch 00033: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 34/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.7662 - vae_r_loss: 0.9046 - vae_kl_loss: 4.8616\n",
      "\n",
      "Epoch 00034: saving model to ./run/vae/0002_digits\\weights/weights-034-5.77.h5\n",
      "\n",
      "Epoch 00034: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 35/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 5.7571 - vae_r_loss: 0.9019 - vae_kl_loss: 4.8552\n",
      "\n",
      "Epoch 00035: saving model to ./run/vae/0002_digits\\weights/weights-035-5.76.h5\n",
      "\n",
      "Epoch 00035: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 36/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.7367 - vae_r_loss: 0.8835 - vae_kl_loss: 4.8532\n",
      "\n",
      "Epoch 00036: saving model to ./run/vae/0002_digits\\weights/weights-036-5.74.h5\n",
      "\n",
      "Epoch 00036: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 37/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.7263 - vae_r_loss: 0.8761 - vae_kl_loss: 4.8503\n",
      "\n",
      "Epoch 00037: saving model to ./run/vae/0002_digits\\weights/weights-037-5.73.h5\n",
      "\n",
      "Epoch 00037: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 38/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.7004 - vae_r_loss: 0.8654 - vae_kl_loss: 4.8350\n",
      "\n",
      "Epoch 00038: saving model to ./run/vae/0002_digits\\weights/weights-038-5.70.h5\n",
      "\n",
      "Epoch 00038: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 39/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.7200 - vae_r_loss: 0.8644 - vae_kl_loss: 4.8556\n",
      "\n",
      "Epoch 00039: saving model to ./run/vae/0002_digits\\weights/weights-039-5.72.h5\n",
      "\n",
      "Epoch 00039: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 40/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 5.6739 - vae_r_loss: 0.8513 - vae_kl_loss: 4.82262s - loss: 5.6796 - vae_r_loss: 0.8546 - v - ETA: 1s - l\n",
      "\n",
      "Epoch 00040: saving model to ./run/vae/0002_digits\\weights/weights-040-5.67.h5\n",
      "\n",
      "Epoch 00040: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 41/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 5.6974 - vae_r_loss: 0.8566 - vae_kl_loss: 4.8409\n",
      "\n",
      "Epoch 00041: saving model to ./run/vae/0002_digits\\weights/weights-041-5.70.h5\n",
      "\n",
      "Epoch 00041: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 42/200\n",
      "1875/1875 [==============================] - 30s 16ms/step - loss: 5.6441 - vae_r_loss: 0.8332 - vae_kl_loss: 4.8109\n",
      "\n",
      "Epoch 00042: saving model to ./run/vae/0002_digits\\weights/weights-042-5.64.h5\n",
      "\n",
      "Epoch 00042: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 43/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.6594 - vae_r_loss: 0.8416 - vae_kl_loss: 4.8178\n",
      "\n",
      "Epoch 00043: saving model to ./run/vae/0002_digits\\weights/weights-043-5.66.h5\n",
      "\n",
      "Epoch 00043: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 44/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.6478 - vae_r_loss: 0.8329 - vae_kl_loss: 4.8149\n",
      "\n",
      "Epoch 00044: saving model to ./run/vae/0002_digits\\weights/weights-044-5.65.h5\n",
      "\n",
      "Epoch 00044: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 45/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.6530 - vae_r_loss: 0.8245 - vae_kl_loss: 4.8286\n",
      "\n",
      "Epoch 00045: saving model to ./run/vae/0002_digits\\weights/weights-045-5.65.h5\n",
      "\n",
      "Epoch 00045: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 46/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.6113 - vae_r_loss: 0.8125 - vae_kl_loss: 4.79891s - loss: 5.6133 - \n",
      "\n",
      "Epoch 00046: saving model to ./run/vae/0002_digits\\weights/weights-046-5.61.h5\n",
      "\n",
      "Epoch 00046: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 47/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.6163 - vae_r_loss: 0.8089 - vae_kl_loss: 4.8073\n",
      "\n",
      "Epoch 00047: saving model to ./run/vae/0002_digits\\weights/weights-047-5.62.h5\n",
      "\n",
      "Epoch 00047: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 48/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.6294 - vae_r_loss: 0.8149 - vae_kl_loss: 4.8145\n",
      "\n",
      "Epoch 00048: saving model to ./run/vae/0002_digits\\weights/weights-048-5.63.h5\n",
      "\n",
      "Epoch 00048: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 49/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.6007 - vae_r_loss: 0.8087 - vae_kl_loss: 4.7920\n",
      "\n",
      "Epoch 00049: saving model to ./run/vae/0002_digits\\weights/weights-049-5.60.h5\n",
      "\n",
      "Epoch 00049: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 50/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.5960 - vae_r_loss: 0.7999 - vae_kl_loss: 4.7961\n",
      "\n",
      "Epoch 00050: saving model to ./run/vae/0002_digits\\weights/weights-050-5.60.h5\n",
      "\n",
      "Epoch 00050: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 51/200\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 5.5959 - vae_r_loss: 0.7965 - vae_kl_loss: 4.7994\n",
      "\n",
      "Epoch 00051: saving model to ./run/vae/0002_digits\\weights/weights-051-5.60.h5\n",
      "\n",
      "Epoch 00051: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 52/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 5.5520 - vae_r_loss: 0.7826 - vae_kl_loss: 4.7695\n",
      "\n",
      "Epoch 00052: saving model to ./run/vae/0002_digits\\weights/weights-052-5.55.h5\n",
      "\n",
      "Epoch 00052: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 53/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.5633 - vae_r_loss: 0.7792 - vae_kl_loss: 4.7841\n",
      "\n",
      "Epoch 00053: saving model to ./run/vae/0002_digits\\weights/weights-053-5.56.h5\n",
      "\n",
      "Epoch 00053: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 54/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.5704 - vae_r_loss: 0.7782 - vae_kl_loss: 4.7921\n",
      "\n",
      "Epoch 00054: saving model to ./run/vae/0002_digits\\weights/weights-054-5.57.h5\n",
      "\n",
      "Epoch 00054: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 55/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.5758 - vae_r_loss: 0.7766 - vae_kl_loss: 4.79920s - loss: 5.5764 - vae_r_loss: 0.7772 - vae_kl_loss: 4.\n",
      "\n",
      "Epoch 00055: saving model to ./run/vae/0002_digits\\weights/weights-055-5.58.h5\n",
      "\n",
      "Epoch 00055: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 56/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.5269 - vae_r_loss: 0.7639 - vae_kl_loss: 4.7630\n",
      "\n",
      "Epoch 00056: saving model to ./run/vae/0002_digits\\weights/weights-056-5.53.h5\n",
      "\n",
      "Epoch 00056: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 57/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.5408 - vae_r_loss: 0.7692 - vae_kl_loss: 4.7717\n",
      "\n",
      "Epoch 00057: saving model to ./run/vae/0002_digits\\weights/weights-057-5.54.h5\n",
      "\n",
      "Epoch 00057: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.5404 - vae_r_loss: 0.7538 - vae_kl_loss: 4.7866\n",
      "\n",
      "Epoch 00058: saving model to ./run/vae/0002_digits\\weights/weights-058-5.54.h5\n",
      "\n",
      "Epoch 00058: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 59/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.5089 - vae_r_loss: 0.7369 - vae_kl_loss: 4.7720\n",
      "\n",
      "Epoch 00059: saving model to ./run/vae/0002_digits\\weights/weights-059-5.51.h5\n",
      "\n",
      "Epoch 00059: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 60/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.5299 - vae_r_loss: 0.7478 - vae_kl_loss: 4.78220s - loss: 5.5328 - vae_r_lo\n",
      "\n",
      "Epoch 00060: saving model to ./run/vae/0002_digits\\weights/weights-060-5.53.h5\n",
      "\n",
      "Epoch 00060: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 61/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4861 - vae_r_loss: 0.7252 - vae_kl_loss: 4.7609\n",
      "\n",
      "Epoch 00061: saving model to ./run/vae/0002_digits\\weights/weights-061-5.49.h5\n",
      "\n",
      "Epoch 00061: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 62/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4933 - vae_r_loss: 0.7210 - vae_kl_loss: 4.77230s - loss: 5.4913 - vae_r_loss: 0.7205 - v\n",
      "\n",
      "Epoch 00062: saving model to ./run/vae/0002_digits\\weights/weights-062-5.49.h5\n",
      "\n",
      "Epoch 00062: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 63/200\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 5.4838 - vae_r_loss: 0.7281 - vae_kl_loss: 4.7558\n",
      "\n",
      "Epoch 00063: saving model to ./run/vae/0002_digits\\weights/weights-063-5.48.h5\n",
      "\n",
      "Epoch 00063: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 64/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.4948 - vae_r_loss: 0.7248 - vae_kl_loss: 4.77010s - loss: 5.4933 - vae_r_loss: 0.7247 - vae\n",
      "\n",
      "Epoch 00064: saving model to ./run/vae/0002_digits\\weights/weights-064-5.49.h5\n",
      "\n",
      "Epoch 00064: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 65/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4695 - vae_r_loss: 0.7141 - vae_kl_loss: 4.7555\n",
      "\n",
      "Epoch 00065: saving model to ./run/vae/0002_digits\\weights/weights-065-5.47.h5\n",
      "\n",
      "Epoch 00065: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 66/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4922 - vae_r_loss: 0.7192 - vae_kl_loss: 4.7730\n",
      "\n",
      "Epoch 00066: saving model to ./run/vae/0002_digits\\weights/weights-066-5.49.h5\n",
      "\n",
      "Epoch 00066: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 67/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4493 - vae_r_loss: 0.7000 - vae_kl_loss: 4.7493\n",
      "\n",
      "Epoch 00067: saving model to ./run/vae/0002_digits\\weights/weights-067-5.45.h5\n",
      "\n",
      "Epoch 00067: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 68/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4836 - vae_r_loss: 0.7235 - vae_kl_loss: 4.7601\n",
      "\n",
      "Epoch 00068: saving model to ./run/vae/0002_digits\\weights/weights-068-5.48.h5\n",
      "\n",
      "Epoch 00068: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 69/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4832 - vae_r_loss: 0.7132 - vae_kl_loss: 4.7700\n",
      "\n",
      "Epoch 00069: saving model to ./run/vae/0002_digits\\weights/weights-069-5.48.h5\n",
      "\n",
      "Epoch 00069: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 70/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.4425 - vae_r_loss: 0.7011 - vae_kl_loss: 4.7414\n",
      "\n",
      "Epoch 00070: saving model to ./run/vae/0002_digits\\weights/weights-070-5.44.h5\n",
      "\n",
      "Epoch 00070: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 71/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4510 - vae_r_loss: 0.7056 - vae_kl_loss: 4.7454\n",
      "\n",
      "Epoch 00071: saving model to ./run/vae/0002_digits\\weights/weights-071-5.45.h5\n",
      "\n",
      "Epoch 00071: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 72/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.4257 - vae_r_loss: 0.6856 - vae_kl_loss: 4.7401\n",
      "\n",
      "Epoch 00072: saving model to ./run/vae/0002_digits\\weights/weights-072-5.43.h5\n",
      "\n",
      "Epoch 00072: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 73/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.4387 - vae_r_loss: 0.6953 - vae_kl_loss: 4.7434\n",
      "\n",
      "Epoch 00073: saving model to ./run/vae/0002_digits\\weights/weights-073-5.44.h5\n",
      "\n",
      "Epoch 00073: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 74/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 5.4496 - vae_r_loss: 0.6962 - vae_kl_loss: 4.7535\n",
      "\n",
      "Epoch 00074: saving model to ./run/vae/0002_digits\\weights/weights-074-5.45.h5\n",
      "\n",
      "Epoch 00074: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 75/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.4283 - vae_r_loss: 0.6841 - vae_kl_loss: 4.7442\n",
      "\n",
      "Epoch 00075: saving model to ./run/vae/0002_digits\\weights/weights-075-5.43.h5\n",
      "\n",
      "Epoch 00075: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 76/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4148 - vae_r_loss: 0.6864 - vae_kl_loss: 4.7284\n",
      "\n",
      "Epoch 00076: saving model to ./run/vae/0002_digits\\weights/weights-076-5.41.h5\n",
      "\n",
      "Epoch 00076: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 77/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4353 - vae_r_loss: 0.6836 - vae_kl_loss: 4.7517\n",
      "\n",
      "Epoch 00077: saving model to ./run/vae/0002_digits\\weights/weights-077-5.44.h5\n",
      "\n",
      "Epoch 00077: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 78/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.4093 - vae_r_loss: 0.6749 - vae_kl_loss: 4.7343\n",
      "\n",
      "Epoch 00078: saving model to ./run/vae/0002_digits\\weights/weights-078-5.41.h5\n",
      "\n",
      "Epoch 00078: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 79/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 5.4112 - vae_r_loss: 0.6771 - vae_kl_loss: 4.73402s - loss: 5.414 - ETA: 1s - loss: 5.4\n",
      "\n",
      "Epoch 00079: saving model to ./run/vae/0002_digits\\weights/weights-079-5.41.h5\n",
      "\n",
      "Epoch 00079: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 80/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.4093 - vae_r_loss: 0.6755 - vae_kl_loss: 4.7337\n",
      "\n",
      "Epoch 00080: saving model to ./run/vae/0002_digits\\weights/weights-080-5.41.h5\n",
      "\n",
      "Epoch 00080: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 81/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3942 - vae_r_loss: 0.6763 - vae_kl_loss: 4.7179\n",
      "\n",
      "Epoch 00081: saving model to ./run/vae/0002_digits\\weights/weights-081-5.39.h5\n",
      "\n",
      "Epoch 00081: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 82/200\n",
      "1875/1875 [==============================] - 34s 18ms/step - loss: 5.4071 - vae_r_loss: 0.6718 - vae_kl_loss: 4.7353\n",
      "\n",
      "Epoch 00082: saving model to ./run/vae/0002_digits\\weights/weights-082-5.41.h5\n",
      "\n",
      "Epoch 00082: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 83/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3985 - vae_r_loss: 0.6739 - vae_kl_loss: 4.7246\n",
      "\n",
      "Epoch 00083: saving model to ./run/vae/0002_digits\\weights/weights-083-5.40.h5\n",
      "\n",
      "Epoch 00083: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 84/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.4037 - vae_r_loss: 0.6743 - vae_kl_loss: 4.7295\n",
      "\n",
      "Epoch 00084: saving model to ./run/vae/0002_digits\\weights/weights-084-5.40.h5\n",
      "\n",
      "Epoch 00084: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 85/200\n",
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.4180 - vae_r_loss: 0.6764 - vae_kl_loss: 4.7416\n",
      "\n",
      "Epoch 00085: saving model to ./run/vae/0002_digits\\weights/weights-085-5.42.h5\n",
      "\n",
      "Epoch 00085: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 31s 17ms/step - loss: 5.4103 - vae_r_loss: 0.6712 - vae_kl_loss: 4.7392\n",
      "\n",
      "Epoch 00086: saving model to ./run/vae/0002_digits\\weights/weights-086-5.41.h5\n",
      "\n",
      "Epoch 00086: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 87/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3731 - vae_r_loss: 0.6569 - vae_kl_loss: 4.7162\n",
      "\n",
      "Epoch 00087: saving model to ./run/vae/0002_digits\\weights/weights-087-5.37.h5\n",
      "\n",
      "Epoch 00087: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 88/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3634 - vae_r_loss: 0.6541 - vae_kl_loss: 4.7094\n",
      "\n",
      "Epoch 00088: saving model to ./run/vae/0002_digits\\weights/weights-088-5.36.h5\n",
      "\n",
      "Epoch 00088: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 89/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3774 - vae_r_loss: 0.6636 - vae_kl_loss: 4.7137\n",
      "\n",
      "Epoch 00089: saving model to ./run/vae/0002_digits\\weights/weights-089-5.38.h5\n",
      "\n",
      "Epoch 00089: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 90/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3494 - vae_r_loss: 0.6476 - vae_kl_loss: 4.7018\n",
      "\n",
      "Epoch 00090: saving model to ./run/vae/0002_digits\\weights/weights-090-5.35.h5\n",
      "\n",
      "Epoch 00090: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 91/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3685 - vae_r_loss: 0.6536 - vae_kl_loss: 4.7149\n",
      "\n",
      "Epoch 00091: saving model to ./run/vae/0002_digits\\weights/weights-091-5.37.h5\n",
      "\n",
      "Epoch 00091: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 92/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3565 - vae_r_loss: 0.6475 - vae_kl_loss: 4.7090\n",
      "\n",
      "Epoch 00092: saving model to ./run/vae/0002_digits\\weights/weights-092-5.36.h5\n",
      "\n",
      "Epoch 00092: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 93/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3766 - vae_r_loss: 0.6570 - vae_kl_loss: 4.7196\n",
      "\n",
      "Epoch 00093: saving model to ./run/vae/0002_digits\\weights/weights-093-5.38.h5\n",
      "\n",
      "Epoch 00093: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 94/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3529 - vae_r_loss: 0.6500 - vae_kl_loss: 4.7028\n",
      "\n",
      "Epoch 00094: saving model to ./run/vae/0002_digits\\weights/weights-094-5.35.h5\n",
      "\n",
      "Epoch 00094: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 95/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3489 - vae_r_loss: 0.6455 - vae_kl_loss: 4.7034\n",
      "\n",
      "Epoch 00095: saving model to ./run/vae/0002_digits\\weights/weights-095-5.35.h5\n",
      "\n",
      "Epoch 00095: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 96/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3874 - vae_r_loss: 0.6576 - vae_kl_loss: 4.7299\n",
      "\n",
      "Epoch 00096: saving model to ./run/vae/0002_digits\\weights/weights-096-5.39.h5\n",
      "\n",
      "Epoch 00096: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 97/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3565 - vae_r_loss: 0.6489 - vae_kl_loss: 4.7076\n",
      "\n",
      "Epoch 00097: saving model to ./run/vae/0002_digits\\weights/weights-097-5.36.h5\n",
      "\n",
      "Epoch 00097: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 98/200\n",
      "1875/1875 [==============================] - 33s 17ms/step - loss: 5.3302 - vae_r_loss: 0.6340 - vae_kl_loss: 4.6962\n",
      "\n",
      "Epoch 00098: saving model to ./run/vae/0002_digits\\weights/weights-098-5.33.h5\n",
      "\n",
      "Epoch 00098: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 99/200\n",
      "1875/1875 [==============================] - 33s 18ms/step - loss: 5.3724 - vae_r_loss: 0.6534 - vae_kl_loss: 4.7190\n",
      "\n",
      "Epoch 00099: saving model to ./run/vae/0002_digits\\weights/weights-099-5.37.h5\n",
      "\n",
      "Epoch 00099: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 100/200\n",
      "1875/1875 [==============================] - 32s 17ms/step - loss: 5.3673 - vae_r_loss: 0.6544 - vae_kl_loss: 4.7129\n",
      "\n",
      "Epoch 00100: saving model to ./run/vae/0002_digits\\weights/weights-100-5.37.h5\n",
      "\n",
      "Epoch 00100: saving model to ./run/vae/0002_digits\\weights/weights.h5\n",
      "Epoch 101/200\n",
      "1402/1875 [=====================>........] - ETA: 8s - loss: 5.3522 - vae_r_loss: 0.6387 - vae_kl_loss: 4.7135 - ETA: 9"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-c5f7f7a8a63a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mrun_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRUN_FOLDER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;33m,\u001b[0m \u001b[0mprint_every_n_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mINITIAL_EPOCH\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n",
      "\u001b[1;32mD:\\Steradian\\Personal\\GANs\\models\\VAE.py\u001b[0m in \u001b[0;36mtrain_with_generator\u001b[1;34m(self, data_flow, epochs, steps_per_epoch, run_folder, print_every_n_batches, initial_epoch, lr_decay)\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0minitial_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m             \u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m             )\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\Continuum\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vae.train_with_generator(     \n",
    "    data_gen_obj\n",
    "    , epochs = EPOCHS\n",
    "    , steps_per_epoch = STEPS_PER_EPOCH\n",
    "    , run_folder = RUN_FOLDER\n",
    "    , print_every_n_batches = PRINT_EVERY_N_BATCHES\n",
    "    , initial_epoch = INITIAL_EPOCH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
